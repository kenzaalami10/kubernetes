
[devops@DEVAD1M ~]$ cat kube-flannel.yaml
apiVersion: v1
kind: Namespace
metadata:
  labels:
    k8s-app: flannel
    pod-security.kubernetes.io/enforce: privileged
  name: kube-flannel
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    k8s-app: flannel
  name: flannel
  namespace: kube-flannel
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    k8s-app: flannel
  name: flannel
rules:
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - get
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - nodes/status
  verbs:
  - patch
- apiGroups:
  - networking.k8s.io
  resources:
  - clustercidrs
  verbs:
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    k8s-app: flannel
  name: flannel
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: flannel
subjects:
- kind: ServiceAccount
  name: flannel
  namespace: kube-flannel
---
apiVersion: v1
data:
  cni-conf.json: |
    {
      "name": "cbr0",
      "cniVersion": "0.3.1",
      "plugins": [
        {
          "type": "flannel",
          "delegate": {
            "hairpinMode": true,
            "isDefaultGateway": true
          }
        },
        {
          "type": "portmap",
          "capabilities": {
            "portMappings": true
          }
        }
      ]
    }
  net-conf.json: |
    {
      "Network": "10.244.0.0/16",
      "Backend": {
        "Type": "vxlan"
      }
    }
kind: ConfigMap
metadata:
  labels:
    app: flannel
    k8s-app: flannel
    tier: node
  name: kube-flannel-cfg
  namespace: kube-flannel
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  labels:
    app: flannel
    k8s-app: flannel
    tier: node
  name: kube-flannel-ds
  namespace: kube-flannel
spec:
  selector:
    matchLabels:
      app: flannel
      k8s-app: flannel
  template:
    metadata:
      labels:
        app: flannel
        k8s-app: flannel
        tier: node
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: kubernetes.io/os
                operator: In
                values:
                - linux
      containers:
      - args:
        - --ip-masq
        - --kube-subnet-mgr
        command:
        - /opt/bin/flanneld
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: EVENT_QUEUE_DEPTH
          value: "5000"
        image: 10.173.181.26/flannel/flannel:v0.25.1
        name: kube-flannel
        resources:
          requests:
            cpu: 100m
            memory: 50Mi
        securityContext:
          capabilities:
            add:
            - NET_ADMIN
            - NET_RAW
          privileged: false
        volumeMounts:
        - mountPath: /run/flannel
          name: run
        - mountPath: /etc/kube-flannel/
          name: flannel-cfg
        - mountPath: /run/xtables.lock
          name: xtables-lock
      hostNetwork: true
      initContainers:
      - args:
        - -f
        - /flannel
        - /opt/cni/bin/flannel
        command:
        - cp
        image: 10.173.181.26/flannel/flannel-cni-plugin:v1.4.0-flannel1
        name: install-cni-plugin
        volumeMounts:
        - mountPath: /opt/cni/bin
          name: cni-plugin
      - args:
        - -f
        - /etc/kube-flannel/cni-conf.json
        - /etc/cni/net.d/10-flannel.conflist
        command:
        - cp
        image: 10.173.181.26/flannel/flannel:v0.25.1
        name: install-cni
        volumeMounts:
        - mountPath: /etc/cni/net.d
          name: cni
        - mountPath: /etc/kube-flannel/
          name: flannel-cfg
      priorityClassName: system-node-critical
      serviceAccountName: flannel
      tolerations:
      - effect: NoSchedule
        operator: Exists
      volumes:
      - hostPath:
          path: /run/flannel
        name: run
      - hostPath:
          path: /opt/cni/bin
        name: cni-plugin
      - hostPath:
          path: /etc/cni/net.d
        name: cni
      - configMap:
          name: kube-flannel-cfg
        name: flannel-cfg
      - hostPath:
          path: /run/xtables.lock
          type: FileOrCreate
        name: xtables-lock
[devops@DEVAD1M ~]$ ^C
[devops@DEVAD1M ~]$ kubectl logs -n kube-flannel -l app=flannel -c install-cni-plugin
[devops@DEVAD1M ~]$ kubectl logs -n kube-flannel -l app=flannel -c install-cni
[devops@DEVAD1M ~]$ ls /etc/cni/net.d
10-flannel.conflist
[devops@DEVAD1M ~]$ sudo restart kubelet
sudo: restartÂ : commande introuvable
[devops@DEVAD1M ~]$ sudo systemctl restart kubelet
[devops@DEVAD1M ~]$ kubectl delete pod -n kube-system -l k8s-app=kube-dns --force
Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.
pod "coredns-58767d876d-79c4q" force deleted
pod "coredns-58767d876d-plsfq" force deleted
[devops@DEVAD1M ~]$ kubectl get pods -A
NAMESPACE      NAME                              READY   STATUS              RESTARTS        AGE
kube-flannel   kube-flannel-ds-w8jv2             1/1     Running             0               21m
kube-system    coredns-58767d876d-fbsdk          0/1     ContainerCreating   0               15s
kube-system    coredns-58767d876d-vfgtp          0/1     ContainerCreating   0               15s
kube-system    etcd-devad1m                      1/1     Running             2               5h16m
kube-system    kube-apiserver-devad1m            1/1     Running             2 (5h17m ago)   5h16m
kube-system    kube-controller-manager-devad1m   1/1     Running             2               5h16m
kube-system    kube-proxy-skl2m                  1/1     Running             0               5h16m
kube-system    kube-scheduler-devad1m            1/1     Running             2               5h16m
[devops@DEVAD1M ~]$ kubectl describe  pods coredns-58767d876d-fbsdk -n kube-system
Name:                 coredns-58767d876d-fbsdk
Namespace:            kube-system
Priority:             2000000000
Priority Class Name:  system-cluster-critical
Service Account:      coredns
Node:                 devad1m/10.173.144.180
Start Time:           Wed, 12 Jun 2024 13:31:11 +0100
Labels:               k8s-app=kube-dns
                      pod-template-hash=58767d876d
Annotations:          <none>
Status:               Pending
IP:
IPs:                  <none>
Controlled By:        ReplicaSet/coredns-58767d876d
Containers:
  coredns:
    Container ID:
    Image:         10.173.181.26/coredns:v1.11.1
    Image ID:
    Ports:         53/UDP, 53/TCP, 9153/TCP
    Host Ports:    0/UDP, 0/TCP, 0/TCP
    Args:
      -conf
      /etc/coredns/Corefile
    State:          Waiting
      Reason:       ContainerCreating
    Ready:          False
    Restart Count:  0
    Limits:
      memory:  170Mi
    Requests:
      cpu:        100m
      memory:     70Mi
    Liveness:     http-get http://:8080/health delay=60s timeout=5s period=10s #success=1 #failure=5
    Readiness:    http-get http://:8181/ready delay=0s timeout=1s period=10s #success=1 #failure=3
    Environment:  <none>
    Mounts:
      /etc/coredns from config-volume (ro)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-vxxlc (ro)
Conditions:
  Type                        Status
  PodReadyToStartContainers   False
  Initialized                 True
  Ready                       False
  ContainersReady             False
  PodScheduled                True
Volumes:
  config-volume:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      coredns
    Optional:  false
  kube-api-access-vxxlc:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   Burstable
Node-Selectors:              kubernetes.io/os=linux
Tolerations:                 CriticalAddonsOnly op=Exists
                             node-role.kubernetes.io/control-plane:NoSchedule
                             node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason                  Age   From               Message
  ----     ------                  ----  ----               -------
  Normal   Scheduled               33s   default-scheduler  Successfully assigned kube-system/coredns-58767d876d-fbsdk to devad1m
  Warning  FailedCreatePodSandBox  32s   kubelet            Failed to create pod sandbox: rpc error: code = Unknown desc = failed to create pod network sandbox k8s_coredns-58767d876d-fbsdk_kube-system_afc165d9-194a-41aa-920b-37ac74d33def_0(2f3b94c8327c39fc7f64bce9948ca82ccfb9943288dd14a555505851ab25b06d): No CNI configuration file in /etc/cni/net.d/. Has your network provider started?
  Warning  FailedCreatePodSandBox  17s   kubelet            Failed to create pod sandbox: rpc error: code = Unknown desc = failed to create pod network sandbox k8s_coredns-58767d876d-fbsdk_kube-system_afc165d9-194a-41aa-920b-37ac74d33def_0(1f847b6305a443dd229d94338def949d19758f1fcbb30e057fce5a4de1170747): No CNI configuration file in /etc/cni/net.d/. Has your network provider started?
  Warning  FailedCreatePodSandBox  6s    kubelet            Failed to create pod sandbox: rpc error: code = Unknown desc = failed to create pod network sandbox k8s_coredns-58767d876d-fbsdk_kube-system_afc165d9-194a-41aa-920b-37ac74d33def_0(0ad9fdbf06832fbc4e7d72245ec423bec045b72911cb4a5accaf1f7d942fb9dd): No CNI configuration file in /etc/cni/net.d/. Has your network provider started?
[devops@DEVAD1M ~]$
