apiVersion: v1
kind: Namespace
metadata:
  name: kube-flannel
  labels:
    pod-security.kubernetes.io/enforce: privileged
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: flannel
  namespace: kube-flannel
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: flannel
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get"]
- apiGroups: [""]
  resources: ["nodes"]
  verbs: ["get", "list", "watch"]
- apiGroups: [""]
  resources: ["nodes/status"]
  verbs: ["patch"]
- apiGroups: ["networking.k8s.io"]
  resources: ["clustercidrs"]
  verbs: ["list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: flannel
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: flannel
subjects:
- kind: ServiceAccount
  name: flannel
  namespace: kube-flannel
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: kube-flannel-cfg
  namespace: kube-flannel
data:
  cni-conf.json: |
    {
      "name": "cbr0",
      "cniVersion": "0.3.1",
      "plugins": [
        {
          "type": "flannel",
          "delegate": {
            "hairpinMode": true,
            "isDefaultGateway": true
          }
        },
        {
          "type": "portmap",
          "capabilities": {
            "portMappings": true
          }
        }
      ]
    }
  net-conf.json: |
    {
      "Network": "10.10.0.0/16",
      "Backend": {
        "Type": "vxlan"
      }
    }
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: kube-flannel-ds
  namespace: kube-flannel
spec:
  selector:
    matchLabels:
      app: flannel
  template:
    metadata:
      labels:
        app: flannel
    spec:
      containers:
      - name: kube-flannel
        image: 10.173.181.26/flannel/flannel:v0.25.1
        command: ["/opt/bin/flanneld", "--ip-masq", "--kube-subnet-mgr"]
        resources:
          requests:
            cpu: "100m"
            memory: "50Mi"
        securityContext:
          privileged: true
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        volumeMounts:
        - mountPath: /run/flannel
          name: run
        - mountPath: /etc/kube-flannel/
          name: flannel-cfg
      initContainers:
      - name: install-cni
        image: 10.173.181.26/flannel/flannel:v0.25.1
        command: ["cp", "-f", "/etc/kube-flannel/cni-conf.json", "/etc/cni/net.d/10-flannel.conflist"]
        volumeMounts:
        - mountPath: /etc/cni/net.d
          name: cni
        - mountPath: /etc/kube-flannel/
          name: flannel-cfg
      hostNetwork: true
      serviceAccountName: flannel
      tolerations:
      - operator: Exists
      volumes:
      - name: run
        hostPath:
          path: /run/flannel
      - name: cni
        hostPath:
          path: /etc/cni/net.d
      - name: flannel-cfg
        configMap:
          name: kube-flannel-cfg

[devops@worker1 ~]$ rm kube-flannel.yaml
[devops@worker1 ~]$ vi kube-flannel.yaml
[devops@worker1 ~]$ kubectl apply -f kube-flannel.yaml
namespace/kube-flannel configured
serviceaccount/flannel configured
clusterrole.rbac.authorization.k8s.io/flannel configured
clusterrolebinding.rbac.authorization.k8s.io/flannel configured
configmap/kube-flannel-cfg configured
The DaemonSet "kube-flannel-ds" is invalid: spec.selector: Invalid value: v1.LabelSelector{MatchLabels:map[string]string{"app":"flannel"}, MatchExpressions:[]v1.LabelSelectorRequirement(nil)}: field is immutable
[devops@worker1 ~]$ kubectl get pods -A
NAMESPACE      NAME                              READY   STATUS              RESTARTS        AGE
kube-flannel   kube-flannel-ds-qq7gf             0/1     CrashLoopBackOff    6 (4m33s ago)   10m
kube-system    coredns-58767d876d-5g4ns          0/1     ContainerCreating   0               7m37s
kube-system    coredns-58767d876d-nx7w8          0/1     CrashLoopBackOff    7 (2m2s ago)    13m
kube-system    etcd-worker1                      1/1     Running             1               13m
kube-system    kube-apiserver-worker1            1/1     Running             1               13m
kube-system    kube-controller-manager-worker1   1/1     Running             1               13m
kube-system    kube-proxy-2t6rg                  1/1     Running             0               13m
kube-system    kube-scheduler-worker1            1/1     Running             1               13m
[devops@worker1 ~]$ kubectl get pods -A
NAMESPACE      NAME                              READY   STATUS              RESTARTS        AGE
kube-flannel   kube-flannel-ds-qq7gf             0/1     CrashLoopBackOff    6 (4m36s ago)   10m
kube-system    coredns-58767d876d-5g4ns          0/1     ContainerCreating   0               7m40s
kube-system    coredns-58767d876d-nx7w8          0/1     CrashLoopBackOff    7 (2m5s ago)    13m
kube-system    etcd-worker1                      1/1     Running             1               13m
kube-system    kube-apiserver-worker1            1/1     Running             1               13m
kube-system    kube-controller-manager-worker1   1/1     Running             1               13m
kube-system    kube-proxy-2t6rg                  1/1     Running             0               13m
kube-system    kube-scheduler-worker1            1/1     Running             1               13m
[devops@worker1 ~]$ cat kube-flannel.yaml
